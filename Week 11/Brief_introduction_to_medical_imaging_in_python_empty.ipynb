{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brief introduction to medical imaging in python_empty.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtixSbODHcb0"
      },
      "source": [
        "# **INTRODUCTION TO MEDICAL IMAGING IN PYTHON**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0yhEyde85aH"
      },
      "source": [
        "\n",
        "# OBJECTIVE\n",
        "\n",
        "Information from medical images represents one of the important sources of information in the field of Biomedical Data Science. However, the complexity of this type of structured data requires specific tools and procedures in order to maximize the information that can be obtained from these images.\n",
        "\n",
        "The main objective of this practical session is to become familiar with the handling and processing of medical images. \n",
        "\n",
        "The following practical session is divided in three main blocks:\n",
        "* In the first block we will study how to read different formats of biomedical images as well as how to extract the crucial metadata for their correct interpretation.\n",
        "* In the second block we will focus on basic image processing operations and the application of different coordinate transformations.\n",
        "* In the last block we will define and apply a complete processing pipeline for neuroimaging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12UuVpRN9PdW"
      },
      "source": [
        "# MATERIALS\n",
        "\n",
        "* In this practical lesson we will use the following images\n",
        "    * *TCIA-DICOM/1-014.dcm* This DICOM file provide from TCIA-GBM open dataset.\n",
        "    * *IVY_GAP_W01* This folder contains different MRI image from a single brain tumor study.\n",
        "    * *MNI_ATLAS* This folder contains the MRI MNI atlas.\n",
        "* The images needed for this practice are available through the following link.\n",
        "* In order to work with these images from google colab, you can upload them to your Google Drive space.\n",
        "* Then just run the following code to mount your google drive and have it accessible from colab. \n",
        "\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3WsSthelrGm"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# METHODOLOGY\n",
        "# Part 1 - Medical image handling (loading, basic processing and saving)\n",
        "\n",
        "## 1.1. Introduction \n",
        "\n",
        "\n",
        "*   In this first part of the lab we will see how to read DICOM and NIFTI files in python and extract the image information and its contextual metadata. \n",
        "*   We will also apply basic operations seen in theory to the images. These include intensity changes, contrast changes, histogram matching, and application of common filters such as gaussian or edge enhancement. \n",
        "*   Finally we will save the generated images as nifti for later viewing and comparison.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2JLT-1JmO-6"
      },
      "source": [
        "## 1.2. Reading a medical image in DICOM format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJlJkxPOsAQ4"
      },
      "source": [
        "### Import the required libaries\n",
        "\n",
        "* To be able to read dicom data we need to import \"dcread\" function from *pydicom* library. \n",
        "* Additionally for being able to plot the image data embeded in the dicom file we will import *matplotlib.pytplot*\n",
        "* Note: to import libraries not pre-included in Google colab you can use the command \"! pip install *requered library*\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L4qNbu3gMw5"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bRsOOMiv8CE"
      },
      "source": [
        "### Load the dicom file \n",
        "Load the dicom file *TCIA-DICOM/1-014.dcm* using the dcmread command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtru7thJuoZ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtDI_B8ywR6p"
      },
      "source": [
        "Explore the metadata asociated with the dicom file. In particular obtain the following parameters:\n",
        "\n",
        "\n",
        "*   Patient ID\n",
        "*   Modality\n",
        "*   Study date\n",
        "*   Image size\n",
        "*   Pixel Spacing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztj-1CSvurez"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYfRFvhN1pLf"
      },
      "source": [
        "The image data is located in the *pixel_array* attribute of the imported dicom object.\n",
        "\n",
        "Now you can plot the image data obtained using imshow from matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kffKpEJu8Fl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmazFvwMyuq0"
      },
      "source": [
        "## 1.3 Reading a medical image in NIFTI format\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMGBDygIzDto"
      },
      "source": [
        "### Import the required libraries\n",
        "Import *nibabel* library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNAnTFGOy69o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLtrMwi90JX9"
      },
      "source": [
        "### Load a nifti file\n",
        "\n",
        "* Use the *nibabel.load* comand to load the *IVY_GAP_W01/T1c/T1.nii* nifti image. \n",
        "* As a result we will obtain a nibabel image object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkQ9zBwhziUd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUaL62WP29jM"
      },
      "source": [
        "As with any Python object, you can inspect *img* to see what attributes it has. We recommend using IPython tab completion for this, but here are some examples of interesting attributes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hn2AsYqzeqb"
      },
      "source": [
        "\n",
        "### Exploring the nibabel object attributtes\n",
        "\n",
        "A nibabel image object is the association of three things:\n",
        "\n",
        "* an N-D array containing the image data;\n",
        "* a (4, 4) affine matrix mapping array coordinates to coordinates in some RAS+ world coordinate space (Coordinate systems and affines);\n",
        "* image metadata in the form of a header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DtXtCle5uWw"
      },
      "source": [
        "#### Affine matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PRetsFA3Kb7"
      },
      "source": [
        "**affine** is the affine array relating array coordinates from the image data array to coordinates in some RAS+ world coordinate system ([Coordinate systems and affines](https://https://nipy.org/nibabel/coordinate_systems.html)):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7rRL0dJ46tl"
      },
      "source": [
        "Print the affine attributte of the nibabel object "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMICSbJm28MB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3TdDuUs50Nh"
      },
      "source": [
        "#### Image metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRqVvGKo5js5"
      },
      "source": [
        "The header of an image contains the image metadata. The information in the header will differ between different image formats. For example, the header information for a NIfTI1 format file differs from the header information for a MINC format file.\n",
        "\n",
        "Our image is a NIfTI1 format image, and it therefore has a NIfTI1 format header:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7TzcOy45-hi"
      },
      "source": [
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haDhsmf06J56"
      },
      "source": [
        "*Note: For the record, srow_x, srow_y, srow_z is the affine matrix of the image. Bitpix is how many bits we use to represent each pixel intensity.*\n",
        "\n",
        "The header of any image will normally have the following methods:\n",
        "\n",
        "* get_data_shape() to get the output shape of the image data array\n",
        "\n",
        "* get_data_dtype() to get the numpy data type in which the image data is stored (or will be stored if you save the image)\n",
        "\n",
        "* get_zooms() to get the voxel sizes in millimeters\n",
        "\n",
        "The last value of header.get_zooms() is the time between scans in milliseconds (for dynamic sequences); this is the equivalent of voxel size on the time axis.\n",
        "\n",
        "Apply these methods to our loaded image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJgkbUdc7mZt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv7B4Cru7Hm-"
      },
      "source": [
        "#### Image data array\n",
        "We can get the data from the nifti object with the get_fdata() method.\n",
        "For the array image, get_fdata() just returns the data array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay3a6pHK69D-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii5Cz_sD-yZf"
      },
      "source": [
        "We can check the shape of the array provided by image_data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVzOX3Xb-5vb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdyheN-m4XF8"
      },
      "source": [
        "Now just select a 2D slice in the middle of the field of view (the one on the middle of the z-axis) to plot it with *imshow* command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybsWrBHT_N2Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRVBS3JY_o7t"
      },
      "source": [
        "## 1.4 Basic processing \n",
        "\n",
        "Our goal now will be to be able to modify the image using some of the basic image processing methods we have seen in the theory classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzibaVHHAhMq"
      },
      "source": [
        "### Use of the histogram to analyze changes in intensity distributions\n",
        "\n",
        "First of all we will analyse the histogram of the image. To do so we can use the *plt.hist* function included in *matplotlib* library. To show the relation between the image and the histogram is convenient to plot both the histogram and an 2D slice (e.g. the one in the middle of the field of view) side by side. \n",
        "\n",
        "Note: To see the results of the brightness and contrast increase we need to plot the images with the same intensity range, if not *imshow* command will reescale intensities and not visible effect will appear. For example we can use vmin = 0 and vmax = 50000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RWShCo6Adnj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm1cl8NqKgpG"
      },
      "source": [
        "### Brightness\n",
        "\n",
        "* We can increase/decrease the brightness of the image by just adding/substracting a constant value to the image intensity matrix(image data array).\n",
        "\n",
        "* To test this we will create a new image data array equal to the used before but adding a constant value to all the values in the image data array.\n",
        "\n",
        "```\n",
        "image_data_bri = image_data + constant\n",
        "```\n",
        "\n",
        "* To check the results we will plot the resulting histogram with and a 2D slice of the image data array  side by side. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "384dxmILJFpu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk8VyCCNM3Ll"
      },
      "source": [
        "### Contrast\n",
        "\n",
        "* We can increase/decrease the contrast of an image by  multiplying/dividing the image by a constant, this widens/shortens the distance between intensity values in the image.\n",
        "\n",
        "* To test this we will create a new image data array equal to the used before but multipliying by a constant value to all the values in the image data array.\n",
        "image_data_contrast = image_data + constant\n",
        "To check the results we will plot the resulting histogram with and a 2D slice of the image data array side by side.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnRufCnPPVj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC2muXpDQHhF"
      },
      "source": [
        "### Histogram equalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxKEYpk14Rli"
      },
      "source": [
        "Histogram equalization is a method in image processing of contrast adjustment using the image's histogram. This method usually increases the global contrast of many images, especially when the image is represented by a narrow range of intensity values. Through this adjustment, the intensities can be better distributed on the histogram utilizing the full range of intensities evenly. This allows for areas of lower local contrast to gain a higher contrast. Histogram equalization accomplishes this by effectively spreading out the highly populated intensity values which use to degrade image contrast (source: [Wiki](https://en.wikipedia.org/wiki/Histogram_equalization)).\n",
        "\n",
        "To test the histogram equalization in our sample image:\n",
        "* We can use the *exposure.equalize_hist* function from *skimage* library\n",
        "\n",
        "* Try to plot the original histogram and original image together with the histogram and resulting image  after equalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69D3CuouQgCT"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl6VJElL52pV"
      },
      "source": [
        "Why does it happens? \n",
        "\n",
        "Try to define a mask that solves this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2IVAH_U10JD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueg2l8ju6FG_"
      },
      "source": [
        "### Filtering\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5RM5NBd_DqI"
      },
      "source": [
        "\n",
        "Convolution Filters (also known as kernels) are used with images for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between a kernel and an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKA2Uk33_uvS"
      },
      "source": [
        "**Gaussian filter**: The Gaussian smoothing filter is a 2-D convolution filter that is used to `blur' images and remove detail and noise. \n",
        "\n",
        "  * Use the *filters.gaussian* command from skimage library to apply the filter on the image.\n",
        "\n",
        "  * Plot the original and filtered images side-by-side and examine the differences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypJAcqYN6rx3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wH5SjxaABU4"
      },
      "source": [
        "**Laplacian filter:** The Laplacian is a 2-D isotropic measure of the 2nd spatial derivative of an image. The Laplacian of an image highlights regions of rapid intensity change and is therefore often used for edge detection. \n",
        "\n",
        "  * Use the *filters.laplace* command from skimage library to apply the filter on the image.\n",
        "\n",
        "  * Plot the original and filtered images side-by-side and examine the differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm2KxAx57fpT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aBsaiJGAbaV"
      },
      "source": [
        "**Custom filter:** By defining a custom kernel we can create our own filters to extract custom features.\n",
        "\n",
        "  * Define your own filter by just defining a 3x3x3 kernel. \n",
        "\n",
        "  * Use the *filters.convolve* command from skimage library to apply the filter on the image.\n",
        "\n",
        "  * Plot the original and filtered images side-by-side and examine the differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4pf5agK9Pug"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Id6wby0AzL1"
      },
      "source": [
        "## 1.5 Affine transforms \n",
        "\n",
        "* Trasformation are crucial to understand and combine medical images\n",
        "* Images (and volumes) can be thought of as fields (or functions) of space.\n",
        "* Some examples are linear transforms are: translation, rotation or scaling \n",
        "* Rotation and scaling can be each written as matrix vector products\n",
        "* We cannot do that for translations. But we can embed translations into a matrix-vector product if we bump up the dimensión by 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzA2dFAGl9m4"
      },
      "source": [
        "Normally we don't apply affine transformations directly on the image headers instead we use libraries or programs that do it for us. \n",
        "But in this case to exemplify what we have seen in the theory classes we can try to apply some basic transformations simply by modifying some parameters of the image header that define its position and orientation. \n",
        "\n",
        "To apply a affine transformation to an image we can extract the affine transformation that represents the position and orientation of the image contained in the nifty file, apply the desired transform and then save back to the image.\n",
        "To do so we will do the following steps:\n",
        "\n",
        "1.   Obtain the affine transform of the image \"img.affine\"\n",
        "2.   Apply the desired transformations to the affine matrix\n",
        "3.   Use the set_qform / set_sform methods of the original image \"img\" to include the new transformation affine to the image header.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysohKPDoCTCG"
      },
      "source": [
        "### Translation\n",
        "\n",
        "* As a first attempt we can try to move 10 mm in the x axis. \n",
        "* To do so we need to add 10 mm to the [0,3] position of the affine matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICtimv6OA7R2"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIMV_E0AC6Os"
      },
      "source": [
        "### Rotation\n",
        "\n",
        "* As a first attempt we can try to rotate the image 45º in a selected axis.\n",
        "* How can we do that?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMqfVMFgC_d0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zuGDKnwpK8F"
      },
      "source": [
        "### Scaling\n",
        "\n",
        "* As a first attemp we can try to enlarge the image two times the original.\n",
        "* How can we do that?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4nIvJN0pdS9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm48Hp4qZWes"
      },
      "source": [
        "# Part 2 -  Basic pipeline for neuroimaging\n",
        "So far we have been studying and applying basic operations to understand the basics of image processing, but when we work on a day-to-day basis we use image processing libraries that allow us to define fast image processing and analysis flows. \n",
        "\n",
        "# Regarding to ANTsPy\n",
        "\n",
        "Advanced Normalization Tools (ANTs) is useful for managing, interpreting and visualizing multidimensional data. ANTs is popularly considered a state-of-the-art medical image registration and segmentation toolkit. ANTsR is an emerging tool supporting standardized multimodality image analysis. ANTs depends on the Insight ToolKit (ITK), a widely used medical image processing library to which ANTs developers contribute.\n",
        "\n",
        "ANTsPy is a Python library which wraps the C++ biomedical image processing library ANTs, matches much of the statistical capabilities of ANTsR, and allows seamless integration with numpy, scikit-learn, and the greater Python community.\n",
        "\n",
        "Due ANTsPyx is not available by default at Google Colab so we need to install it using pip.\n",
        "\n",
        "A basic pipeline for neuroimaging consist on the following steps:\n",
        "\n",
        "\n",
        "1.   Loading the image\n",
        "2.   Resample the images to set a common resolution for the whole dataset.\n",
        "3.   Bias field correction: Bias field signal is a low-frequency and very smooth signal that corrupts MRI images specially those produced by old MRI (Magnetic Resonance Imaging) \n",
        "4.   Denoising: MR images are affected by random noise which limits the accuracy of any quantitative measurements from the data. To remove the noise from MRI is needed  to generate the MR images with high “signal-to-noise ratio”.\n",
        "5.   Registration to a common space\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl8VWAh1vx2j"
      },
      "source": [
        "### Install ANTsPyx\n",
        "Due ANTsPyx is not available by default at Google Colab so we need to install it using !pip.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npHecoicZrKt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wq0xLB5uLk1"
      },
      "source": [
        "### Load the images\n",
        "\n",
        "* Load the image we want to process. To do so we will process the *IVY_GAP_W01/T1c/T1.nii*\n",
        "* Load the image we want to use as a reference for the common space. The reference image to be used will be *MNI_ATLAS/mni_icbm152_t1_tal_nlin_sym_09c.nii*. This image will be used in the \"Register the image to a common reference space\" step. \n",
        "* To do so we can use the command *ants.image_read*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-I8rIJeZiza"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXn1Jt1mwU__"
      },
      "source": [
        "### Resample the image we want to process\n",
        "* To do so we can use the command ants.resample_image\n",
        "* We can resample images to a resolution of 5x5x5 mm. This resolution is not optimal but it will make all the processing faster.\n",
        "* Save the resulting images in nifti using the *ants.image_write*: command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSxHUoA2bWLp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcTK6rtexKM_"
      },
      "source": [
        "### Perform a bias field correction\n",
        "\n",
        "*  What does bieas field correction does? You can find a description on https://simpleitk.readthedocs.io/en/master/link_N4BiasFieldCorrection_docs.html \n",
        "*   To do so we can use the command *ants.n4_bias_field_correction*\n",
        "*   We will use the default parameters.\n",
        "*  Save the resulting images in nifti using the *ants.image_write*: command\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQ5uqj2au5Z"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_opWaQKxhnL"
      },
      "source": [
        "### Remove noise from the images\n",
        "\n",
        "\n",
        "*   To do so we can use the command *ants.denoise_image*\n",
        "*   We will use the default parameters\n",
        "*   Save the resulting images in nifti using the *ants.image_write*: command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_WLKrA2a273"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBfjRzVTxwZU"
      },
      "source": [
        "### Register the image to a common reference space\n",
        "\n",
        "*   To do so we will use the command *ants.registration*\n",
        "*   We will register the image using two different types of transform \"AffineFast\" (affine transformation) and \"SyN\" (a non-linear trasformation) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3y944Q0bR5I"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1EmREY0eIra"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-1MEPlbDuUX"
      },
      "source": [
        "* Save the resulting images in nifti using the *ants.image_write*: command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttQNOMRblZgd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcVCloMoDv_w"
      },
      "source": [
        "* Once we have both images registered to a common space using linear and non-linear transformations we can compare them with the MNI image used as a reference in ITK-Snap"
      ]
    }
  ]
}