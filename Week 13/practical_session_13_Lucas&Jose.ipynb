{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35a6a43-9e15-494f-b78e-97e0b26b99fe",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Practical session 13</h1>\n",
    "<h2 style=\"text-align:center;\">Biomedical Data Science</h2>\n",
    "<h3 style=\"text-align:center;\">Lucas Fayolle & Jose Valero</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a58fe1-0179-4f30-97b9-eadca76d6c26",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64dab6c6-e0ef-4020-abc6-61bc2592537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34105a-b803-4ddd-89c6-e61d305e6dfc",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068ede6c-03bd-49e7-ad41-138bed68375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "    def scipy_rotate(volume):\n",
    "        angles = [-20, -10, -5, 5, 10, 20]\n",
    "        angle = random.choice(angles)\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    augmented_volume.set_shape(volume.shape)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "    volume = rotate(volume)\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155d08b-b9b8-4622-8717-400f8d7f9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(\"processed_data.npz\", x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a986644-55d9-44b6-b4d8-da9f5522a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"processed_data.npz\")\n",
    "x_train = data[\"x_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "x_val = data[\"x_val\"]\n",
    "y_val = data[\"y_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae0493f-3ee4-4b2f-8fbb-c873c79702a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734968667.506334     836 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "batch_size = 2\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd44c5f-328d-4a8b-98c4-1ae891896625",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1042a-79ac-420d-9e25-64851cd46e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd9542-ee16-469a-9211-94b67a076034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c099eb-d18b-4a5d-9aea-e49c0a5fc01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1aac62-e657-4bac-8066-c9770e41d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, validation_dataset, epochs=20):\n",
    "    initial_learning_rate = 0.0001\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "    # Define callbacks\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        f\"{model.name}.keras\", save_best_only=True\n",
    "    )\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=5)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712d36c-f20e-460a-b37b-676660131b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for i, metric in enumerate([\"acc\", \"loss\"]):\n",
    "        ax[i].plot(history.history[metric])\n",
    "        ax[i].plot(history.history[\"val_\" + metric])\n",
    "        ax[i].set_title(f\"Model {metric}\")\n",
    "        ax[i].set_xlabel(\"Epochs\")\n",
    "        ax[i].set_ylabel(metric.capitalize())\n",
    "        ax[i].legend([\"Train\", \"Validation\"])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9aa073-a628-4370-b894-ed402b0fd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, x_val, class_names):\n",
    "    predictions = model.predict(np.expand_dims(x_val[0], axis=0))[0]\n",
    "    scores = [1 - predictions[0], predictions[0]]\n",
    "\n",
    "    for score, name in zip(scores, class_names):\n",
    "        print(\n",
    "            f\"This model is {100 * score:.2f}% confident that the CT scan is {name}.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6774b0f-a970-4665-acbf-2e736d51a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_and_save(\n",
    "    model_fn, \n",
    "    config_name, \n",
    "    config_description, \n",
    "    train_dataset, \n",
    "    validation_dataset, \n",
    "    epochs=20,\n",
    "    results_list=None\n",
    "):\n",
    "    \"\"\"\n",
    "    model_fn: función que construye y retorna un modelo\n",
    "    config_name: nombre corto de la configuración (ej: 'extra_dense')\n",
    "    config_description: descripción más larga\n",
    "    train_dataset, validation_dataset: tus datasets\n",
    "    epochs: número de épocas\n",
    "    results_list: lista donde se guardará la info del experimento\n",
    "    \"\"\"\n",
    "    model = model_fn()\n",
    "    print(f\"\\nEntrenando configuración: {config_name}\")\n",
    "    model.summary()\n",
    "\n",
    "    history = train_model(model, train_dataset, validation_dataset, epochs=epochs)\n",
    "\n",
    "    final_train_acc = history.history[\"acc\"][-1]\n",
    "    final_train_loss = history.history[\"loss\"][-1]\n",
    "    final_val_acc   = history.history[\"val_acc\"][-1]\n",
    "    final_val_loss  = history.history[\"val_loss\"][-1]\n",
    "\n",
    "    results_list.append({\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"config_name\": config_name,\n",
    "        \"config_description\": config_description,\n",
    "        \"final_train_acc\": final_train_acc,\n",
    "        \"final_train_loss\": final_train_loss,\n",
    "        \"final_val_acc\": final_val_acc,\n",
    "        \"final_val_loss\": final_val_loss,\n",
    "    })\n",
    "\n",
    "    print(f\"Finalizado entrenamiento de {config_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31e4b6-2f6c-4ec1-b208-c0d4e1c1acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block_3d(x, filters, activation=\"relu\"):\n",
    "    shortcut = x\n",
    "    x = layers.Conv3D(filters, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "\n",
    "    x = layers.Conv3D(filters, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Add()([shortcut, x])\n",
    "    x = layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def inception_block_3d(x, filters, activation=\"relu\"):\n",
    "    branch1 = layers.Conv3D(filters, kernel_size=1, padding=\"same\", activation=activation)(x)\n",
    "    branch2 = layers.Conv3D(filters, kernel_size=3, padding=\"same\", activation=activation)(x)\n",
    "    branch3 = layers.Conv3D(filters, kernel_size=5, padding=\"same\", activation=activation)(x)\n",
    "    branch4 = layers.MaxPool3D(pool_size=3, strides=1, padding=\"same\")(x)\n",
    "    branch4 = layers.Conv3D(filters, kernel_size=1, padding=\"same\", activation=activation)(branch4)\n",
    "    x = layers.Concatenate(axis=-1)([branch1, branch2, branch3, branch4])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53900d70-a989-4b4b-997c-ff28e0c23fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_3d_cnn(\n",
    "    width=128,\n",
    "    height=128,\n",
    "    depth=64,\n",
    "    initial_filters=[64, 64, 128, 256],\n",
    "    extra_dense=False,\n",
    "    two_conv_per_level=False,\n",
    "    activation=\"relu\",\n",
    "    pooling=\"max\",  # \"max\" o \"avg\"\n",
    "    use_residual=False,\n",
    "    use_inception=False,\n",
    "    name=\"3dcnn\"\n",
    "):\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = inputs\n",
    "    for f in initial_filters:\n",
    "        if use_residual:\n",
    "            x = residual_block_3d(x, f, activation=activation)\n",
    "        elif use_inception:\n",
    "            x = inception_block_3d(x, f, activation=activation)\n",
    "        else:\n",
    "            x = layers.Conv3D(filters=f, kernel_size=3, activation=activation, padding=\"same\")(x)\n",
    "            if two_conv_per_level:\n",
    "                x = layers.Conv3D(filters=f, kernel_size=3, activation=activation, padding=\"same\")(x)\n",
    "\n",
    "        if pooling == \"avg\":\n",
    "            x = layers.AveragePooling3D(pool_size=2)(x)\n",
    "        else:\n",
    "            x = layers.MaxPool3D(pool_size=2)(x)\n",
    "\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "\n",
    "    x = layers.Dense(units=512, activation=activation)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    if extra_dense:\n",
    "        x = layers.Dense(units=100, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e967c92-c369-4d09-a43a-417d4d758520",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    \"original\": {\n",
    "        \"description\": \"Modelo base sin modificaciones\",\n",
    "        \"params\": {\n",
    "            \"extra_dense\": False,\n",
    "            \"two_conv_per_level\": False,\n",
    "            \"activation\": \"relu\",\n",
    "            \"pooling\": \"max\",\n",
    "            \"use_residual\": False,\n",
    "            \"use_inception\": False,\n",
    "        },\n",
    "    },\n",
    "    \"extra_dense\": {\n",
    "        \"description\": \"Añade capa Dense de 100 unidades antes de la salida\",\n",
    "        \"params\": {\n",
    "            \"extra_dense\": True,       # clave\n",
    "            \"two_conv_per_level\": False,\n",
    "            \"activation\": \"relu\",\n",
    "            \"pooling\": \"max\",\n",
    "            \"use_residual\": False,\n",
    "            \"use_inception\": False,\n",
    "        },\n",
    "    },\n",
    "    \"two_conv_per_level\": {\n",
    "        \"description\": \"Agrega una segunda capa Conv3D en cada bloque\",\n",
    "        \"params\": {\n",
    "            \"extra_dense\": False,\n",
    "            \"two_conv_per_level\": True,  # clave\n",
    "            \"activation\": \"relu\",\n",
    "            \"pooling\": \"max\",\n",
    "            \"use_residual\": False,\n",
    "            \"use_inception\": False,\n",
    "        },\n",
    "    },\n",
    "    \"relu_to_sigmoid\": {\n",
    "        \"description\": \"Cambia la activación ReLU por sigmoid en todas las capas\",\n",
    "        \"params\": {\n",
    "            \"extra_dense\": False,\n",
    "            \"two_conv_per_level\": False,\n",
    "            \"activation\": \"sigmoid\",  # clave\n",
    "            \"pooling\": \"max\",\n",
    "            \"use_residual\": False,\n",
    "            \"use_inception\": False,\n",
    "        },\n",
    "    },\n",
    "    \"max_to_avg_pooling\": {\n",
    "        \"description\": \"Usa AveragePooling3D en lugar de MaxPooling3D\",\n",
    "        \"params\": {\n",
    "            \"extra_dense\": False,\n",
    "            \"two_conv_per_level\": False,\n",
    "            \"activation\": \"relu\",\n",
    "            \"pooling\": \"avg\",   # clave\n",
    "            \"use_residual\": False,\n",
    "            \"use_inception\": False,\n",
    "        },\n",
    "    },\n",
    "    \"residual_blocks\": {\n",
    "        \"description\": \"Reemplaza capas conv por bloques residuales\",\n",
    "        \"params\": {\n",
    "            \"extra_dense\": False,\n",
    "            \"two_conv_per_level\": False,\n",
    "            \"activation\": \"relu\",\n",
    "            \"pooling\": \"max\",\n",
    "            \"use_residual\": True,   # clave\n",
    "            \"use_inception\": False,\n",
    "        },\n",
    "    },\n",
    "    \"inception_blocks\": {\n",
    "        \"description\": \"Reemplaza capas conv por bloques inception 3D\",\n",
    "        \"params\": {\n",
    "            \"extra_dense\": False,\n",
    "            \"two_conv_per_level\": False,\n",
    "            \"activation\": \"relu\",\n",
    "            \"pooling\": \"max\",\n",
    "            \"use_residual\": False,\n",
    "            \"use_inception\": True,  # clave\n",
    "        },\n",
    "    },\n",
    "    # Podrías seguir agregando “residual_inception_blocks”, etc.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0ac5d-066b-41b3-9c45-b188147f16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def run_all_experiments(train_dataset, validation_dataset, epochs=20):\n",
    "    results_list = []\n",
    "\n",
    "    for config_name, cfg in models_config.items():\n",
    "        print(f\"\\n=== Entrenando modelo '{config_name}' ===\")\n",
    "        params = cfg[\"params\"]\n",
    "\n",
    "        model = build_3d_cnn(\n",
    "            width=128, \n",
    "            height=128, \n",
    "            depth=64,\n",
    "            **params,          \n",
    "            name=f\"3dcnn_{config_name}\"\n",
    "        )\n",
    "        model.summary()\n",
    "\n",
    "        history = train_model(model, train_dataset, validation_dataset, epochs=epochs)\n",
    "\n",
    "        final_train_acc = history.history[\"acc\"][-1]\n",
    "        final_val_acc   = history.history[\"val_acc\"][-1]\n",
    "\n",
    "        results_list.append({\n",
    "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "            \"config_name\": config_name,\n",
    "            \"description\": cfg[\"description\"],\n",
    "            \"final_train_acc\": final_train_acc,\n",
    "            \"final_val_acc\": final_val_acc,\n",
    "        })\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    df = pd.DataFrame(results_list)\n",
    "    # df.to_csv(\"experimentos.csv\", index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a09fb-b13d-4ece-bf93-ca409bb63199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_all_experiments(train_dataset, validation_dataset, epochs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
